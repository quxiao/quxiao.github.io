---
layout: post
title: "《Infomration Retrieval in Practice》笔记——整体架构"
description: ""
category: ""
tags: []
---
{% include JB/setup %}


对于一个典型的搜索引擎，至少包含两大部分：1）建立索引；2）query查询。

建立索引
=======================

主要流程如下图所示：

![pic]({{site.url}}/images/2013-11-30/index-building.png)

就是获取需要检索的数据，将其转化为系统可以识别的方式，并且做一些预处理。

本文获取 (Text Accquisition)
---------------

** 爬虫 **

本文获取就是将所需要的数据“抓”下来。其中，依据搜索引擎的使用场景不同(网站内部检索/全网检索/文件系统检索/...)，需要检索的数据可以是全网、某个网站的网页、数据库的表、或者磁盘上面的文件等等，这样就需要不同类型的“爬虫”。另外，也可以像`RSS`这样的流式访问数据的标准。

获取到所需要的数据，这只完成了一部分。另外，当数据源有更新时（网页修改/数据库新增了数据/...），爬虫需要能及时的感知并且重新抓取数据提供给检索系统。而且，不同类型的数据，对于实时性的要求是不一样的。比如，一个发布新闻网站和和一个保存历史资料的网站，它们网页的实时性要求肯定是不一样的。

** 转换 **

文本获取到了，需要将其统一成搜索引擎可以识别的格式，文本转换包含两层含义：

* **将不同格式标准的数据转换为统一的格式**

例如，同样的记录书籍内容的文档，一个是`XML`格式的，一个是`JSON`格式的。爬虫如果想获取书籍的名称、作者、`ISBN`等信息，就需要采用不同的解析方式。

* **将不同编码的文本转化为统一编码**

有的网页是`UTF-8`编码的，有的是`GB18030`编码的，都需要统一成一个编码。

** 存储 **

数据（数据本身以及MetaData）获取到了，也转成统一格式了，下面就得想办法把数据持久化。持久化的方式有很多种，比如可以是本地文件系统、分布式文件系统（HDFS）、各种数据库（MYSQL / MongoDB）等等。


文本变形 (Text Transformation)
------------

** 切词 && 归一化 **
检索索引之前，需要先将文本转化为一系列的term，term可以理解为有意义的最小单位词语，比如：

> GitHub is the best place to share code with friends, co-workers, classmates, and complete strangers.

就会生成`github`, `best`, `place`, `share`, `code`, `friend`, `co-worker`, `classmate`, `complete`, `stranger`这些term。其中会将`is`, `the`等没有实际意义的单词去掉，然后做归一化，比如大小写转换，单复数转换等。

中文一句话中没有空格表示停顿，转化term会更复杂，比如上学时老师举的一个例子：

> 南京市长江大桥

应该需要切成`南京市`, `长江`以及`大桥`，而不是`南京`, `市长`, `江大桥`

** 质量度 **

除了获取已经归一化的、数据所需要表达的信息之外，还需要对这份数据本身的质量做一个判断，相当于一个小网站发布的新闻和一个大网站发布的新闻，按照常理明显后者的质量、可信度等因素要优化前者。（在某些国家，事实真的是这样吗？ :P ）。`PageRank`算法就是一个例子，采用迭代的方式，通过网页链接（也就是网页的出度和入度）来计算该网页的质量度。


